{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exciting Stuff\n",
    "\n",
    "In this notebook you will solve a problem that was posed as follows for CS189 Spring 2017 (with minor modifications): \n",
    "\n",
    "\"Jordan is planning the frat party of the semester. Heâ€™s completely stocked up on Franzia. Unfortunately, the\n",
    "labels for 497 boxes (test set) have been scratched off, and he needs to quickly find out which boxes contain\n",
    "Red wine (label 1) and White wine (label 0). Fortunately, for him the boxes still have their Nutrition Facts\n",
    "(features) intact and detail the chemical composition of the wine inside the boxes (the description of these\n",
    "features and the features themselves are provided in data.mat). He also has 6,000 boxes with Nutrition\n",
    "Facts and labels intact (train set). Help Jordan figure out what the labels should be for the 497 mystery boxes.\"\n",
    "\n",
    "Dataset creds: Jonathan Shewchuk's CS189 Spring 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat as loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Functions\n",
    "Fill these in so that we can perform training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(X, w):\n",
    "    \"\"\"\n",
    "    Compute the elementwise sigmoid of the product Xw\n",
    "    Data in X should be rows, weights are a column. \n",
    "    returns: s(Xw)\n",
    "    \"\"\"\n",
    "    return 1/(1 + Math.exp(-np.dot(X, w)))\n",
    "\n",
    "def gradient(X, y, w, onept, lamb=0):\n",
    "    \"\"\"\n",
    "    Compute gradient of regularized loss function. \n",
    "    Accomodate for if X is just one data point. \n",
    "    returns: gradient (should match dimensions of w)\n",
    "    \"\"\"\n",
    "\n",
    "def loss(X, y, w, lamb=0):\n",
    "    \"\"\"\n",
    "    Compute average loss for the data in X, labels in y, params w\n",
    "    returns: scalar value of average loss\n",
    "    \"\"\"\n",
    "    \n",
    "def accuracy(X, y, w):\n",
    "    \"\"\"\n",
    "    Compute accuracy for data in X, labels in y, params w\n",
    "    returns: scalar value of average accuracy\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Data\n",
    "This procedure uses loading a .mat file. The returned object is a dictionary that has numpy arrays as values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "Let's add a bias feature to improve the capacity of our model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent\n",
    "- First instantiate a normalized weight vector.\n",
    "- Create an empty list of loss values which we will fill and visualize.\n",
    "- Perform training using the entire dataset for gradient calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize The Loss \n",
    "- Plot loss values with respect to every training step. \n",
    "- How can you explain the shape that this graph takes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Training Exercise with SGD\n",
    "- Training with respect to only one point instead of the whole dataset. \n",
    "- Plot the losses. Why does the graph take the shape that it does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
